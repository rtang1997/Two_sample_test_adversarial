{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPBEK7EWwfv+LhkbU6BHX/m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"caFL0kO2JGVR"},"outputs":[],"source":["num_mode=10 ###number of mode of prior###\n","import numpy as np\n","\n","import tensorflow.compat.v2 as tf\n","tf.enable_v2_behavior()\n","\n","import tensorflow_datasets as tfds\n","import tensorflow_probability as tfp\n","\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","tfpl = tfp.layers\n","tfd = tfp.distributions\n","datasets, datasets_info = tfds.load(name='mnist',\n","                                    with_info=True,\n","                                    as_supervised=False)\n","\n","def _preprocess(sample):\n","  image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n","  image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.\n","  return image, image\n","\n","train_dataset = (datasets['train']\n","                 .map(_preprocess)\n","                 .batch(128)\n","                 .prefetch(tf.data.AUTOTUNE)\n","                 .shuffle(int(10e3)))\n","input_shape = datasets_info.features['image'].shape\n","encoded_size = 2\n","base_depth = 32\n","tfd = tfp.distributions\n","tfpl = tfp.layers\n","tfb = tfp.bijectors\n"]},{"cell_type":"code","source":["\n","def get_prior(num_modes, latent_dim):\n","    prior = tfd.MixtureSameFamily(\n","        mixture_distribution=tfd.Categorical(probs=[1 / num_modes,] * num_modes),\n","        components_distribution=tfd.MultivariateNormalDiag(\n","            loc=tf.Variable(tf.random.normal(shape=[num_modes, latent_dim])),\n","            scale_diag=tfp.util.TransformedVariable(tf.Variable(tf.ones(shape=[num_modes, latent_dim])), bijector=tfb.Softplus())\n","        )\n","    )\n","    return prior\n","\n","prior = get_prior(num_modes=num_mode, latent_dim=encoded_size)\n"," "],"metadata":{"id":"IG-TUuxeJRzt","executionInfo":{"status":"ok","timestamp":1665863089742,"user_tz":300,"elapsed":240,"user":{"displayName":"Rong Tang","userId":"05174282998092631681"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["encoder = tfk.Sequential([\n","    tfkl.InputLayer(input_shape=input_shape),\n","    tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\n","    tfkl.Conv2D(base_depth, 3, strides=2,\n","                padding='same', activation=tf.nn.leaky_relu),\n","    tfkl.Conv2D(2 * base_depth,3, strides=2,\n","                padding='same', activation=tf.nn.leaky_relu),\n","    tfkl.Flatten(),\n","    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),\n","               activation=None),\n","    tfpl.MultivariateNormalTriL(\n","        encoded_size,\n","        activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n","])"],"metadata":{"id":"_tMb3EQwJYrN","executionInfo":{"status":"ok","timestamp":1665863090272,"user_tz":300,"elapsed":533,"user":{"displayName":"Rong Tang","userId":"05174282998092631681"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from tensorflow import sigmoid\n","decoder = tfk.Sequential([\n","    tfkl.InputLayer(input_shape=[encoded_size]),\n","    tfkl.Dense(6 * 6 * 32, activation=\"relu\"),\n","    tfkl.Reshape([6, 6, 32]),\n","    tfkl.Conv2DTranspose(2 * base_depth, 3, strides=2,\n","                         padding='valid', activation=tf.nn.leaky_relu),\n","    tfkl.Conv2DTranspose( base_depth, 3, strides=2,\n","                         padding='valid', activation=tf.nn.leaky_relu),\n","    tfkl.Conv2DTranspose( 1, 2, strides=1,\n","                         padding='valid', activation=tf.nn.leaky_relu),                   \n","    tfkl.Flatten(),\n","    tfpl.IndependentBernoulli(input_shape, tfd.Distribution.sample),\n","   \n","])"],"metadata":{"id":"-HKBcj6WJbPD","executionInfo":{"status":"ok","timestamp":1665863090477,"user_tz":300,"elapsed":215,"user":{"displayName":"Rong Tang","userId":"05174282998092631681"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["vae = tfk.Model(inputs=encoder.inputs,\n","                outputs=decoder(encoder.outputs[0]))"],"metadata":{"id":"3xECCwPzJgQE","executionInfo":{"status":"ok","timestamp":1665863090478,"user_tz":300,"elapsed":5,"user":{"displayName":"Rong Tang","userId":"05174282998092631681"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n","\n","\n","\n","\n","vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n","            loss=negloglik)\n","\n","_ = vae.fit(train_dataset,\n","            epochs=50 )"],"metadata":{"id":"krXjhbjBJkg9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _preprocess1(sample):\n","  image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n","  image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.\n","  return image, sample['label']"],"metadata":{"id":"8_q4Iv0PJpm8","executionInfo":{"status":"ok","timestamp":1665863520203,"user_tz":300,"elapsed":209,"user":{"displayName":"Rong Tang","userId":"05174282998092631681"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["eval_dataset = (datasets['test']\n","                .map(_preprocess1)\n","                .batch(10000)\n","                .prefetch(tf.data.AUTOTUNE))"],"metadata":{"id":"GxoEv45oJqld","executionInfo":{"status":"ok","timestamp":1665863687856,"user_tz":300,"elapsed":555,"user":{"displayName":"Rong Tang","userId":"05174282998092631681"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["xx = next(iter(eval_dataset))\n","x=xx[0]\n","y=xx[1]"],"metadata":{"id":"aZhZFJnWJuIh","executionInfo":{"status":"ok","timestamp":1665863689413,"user_tz":300,"elapsed":225,"user":{"displayName":"Rong Tang","userId":"05174282998092631681"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["#####compute test LL####\n","from scipy.special import logsumexp\n","T=100\n","K=10\n","w=0\n","stat=[]\n","for j in range(T):\n","  a=[]\n","  for r in range(K):\n","      a1=negloglik(x,decoder(encoder(x)))\n","      a1=tf.expand_dims(a1,axis=0)\n","      a.append(a1)\n","  aa=tf.concat(a,axis=0)\n","  stat.append(np.mean(logsumexp(aa,axis=0)-np.log(K)))\n","  w=w+np.mean(logsumexp(aa,axis=0)-np.log(K))/T\n","print(w)"],"metadata":{"id":"8VAXeLnmJyIw","executionInfo":{"status":"ok","timestamp":1665863553513,"user_tz":300,"elapsed":26669,"user":{"displayName":"Rong Tang","userId":"05174282998092631681"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["###compute statistic T_{\\gamma,J}########\n","get_bin = lambda x, n: format(x, 'b').zfill(n)\n","d=2\n","n=10000\n","####define wavelet basis #####\n","def Tobinary(x):\n","   k=get_bin(x,d)\n","   return([int(numeric_string) for numeric_string in k])\n","def psi(x,index):\n","  if (index==1):\n","    if ((x>=0)&(x<1/2)):\n","        return(1)\n","    elif ((x>=1/2)&(x<=1)):\n","         return(-1)\n","    else:\n","      return (0)\n","  if (index==0):\n","     if((x>=0)&(x<=1)):\n","        return(1)\n","     else:\n","        return(0)\n","def psi1(x,j,k,index):\n","  return(2**(j/2)*psi((2**j)*x-k,index))\n","def getorder(k,j):\n","  a=0\n","  for l in range(d):\n","    a=a+k[l]*2**(l*j)\n","  return(int(a))\n"," \n","def NormalizeData(data):\n","    return (data - np.min(data,axis=0)) / (np.max(data,axis=0) - np.min(data,axis=0))\n","xx = next(iter(eval_dataset))\n","x=xx[0]\n","A=encoder(x).sample(1)\n","Y=tf.squeeze( A, axis=0)\n","Y=Y.numpy()\n","X=prior.sample(10000)\n","X=X.numpy()\n","Z=NormalizeData(np.vstack([X,Y]))\n","X=Z[0:n,]\n","Y=Z[n:(2*n),]\n","###compute wavelet coefficients#######\n","import math\n","J=8\n","coefX1=[]\n","coefX2=[]\n","coefY1=[]\n","coefY2=[]\n","\n","for j in range(J):\n","  coefX1.append(np.zeros((2**(d*j),2**d-1)))\n","  coefX2.append(np.zeros((2**(d*j),2**d-1)))\n","  coefY1.append(np.zeros((2**(d*j),2**d-1)))\n","  coefY2.append(np.zeros((2**(d*j),2**d-1)))\n","for i in  range(n):\n","  x=X[i,]\n","  for j in range(J):\n","    k=np.zeros(d)\n","    for l in range(d):\n","      if((2**j*x[l])%1==0):\n","          k[l]=2**j*x[l]-1\n","      else:\n","          k[l]=math.floor(2**j*x[l])\n","    k1=getorder(k,j) \n","    for l in range(1,2**d):\n","        a=1\n","        index=Tobinary(l)\n","        for ss in range(d):\n","          a=a*psi1(x[ss],j,k[ss],index[ss])\n","        coefX1[j][k1,l-1]=coefX1[j][k1,l-1]+a\n","        coefX2[j][k1,l-1]=coefX2[j][k1,l-1]+a**2\n","\n","for i in  range(n):\n","  x=Y[i,]\n","  for j in range(J):\n","    k=np.zeros(d)\n","    for l in range(d):\n","      if((2**j*x[l])%1==0):\n","        k[l]=2**j*x[l]-1\n","      else:\n","        k[l]=math.floor(2**j*x[l])\n","    k1=getorder(k,j) \n","    for l in range(1,2**d):\n","      a=1\n","      index=Tobinary(l)\n","      for ss in range(d):\n","        a=a*psi1(x[ss],j,k[ss],index[ss])\n","      coefY1[j][k1,l-1]=coefY1[j][k1,l-1]+a\n","      coefY2[j][k1,l-1]=coefY2[j][k1,l-1]+a**2\n","###compute statistic T_{\\gamma,J} based on wavelet coefficients#######\n","T1=0\n","for j in range(J):\n","  for k in range(2**(d*j)):\n","    for l in range(1,2**d):\n","        T1=T1+2**(-2*(j+1)*2/4)*(((coefX1[j][k,l-1])**2-coefX2[j][k,l-1])/(n*(n-1))+((coefY1[j][k,l-1])**2-coefY2[j][k,l-1])/(n*(n-1))-2*coefX1[j][k,l-1]*coefY1[j][k,l-1]/(n*n))\n","  \n","print(T1)"],"metadata":{"id":"tD1DdkuYKS1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NmE4yb_5KVTU"},"execution_count":null,"outputs":[]}]}